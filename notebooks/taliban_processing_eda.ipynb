{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 1: Imports and Configuration complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# --- Configuration ---\n",
    "# Input file from src/scrapers/article_scraper.py\n",
    "TALIBAN_SCRAPED_ARTICLES_JSON = 'data/raw/english_extracted_articles.json'\n",
    "# Pre-generated geocode cache file\n",
    "GEOCODE_CACHE_JSON = 'data/intermediate/cleaned_location_coordinates.json' \n",
    "\n",
    "# Output files for this notebook\n",
    "PROCESSED_TALIBAN_DIR = 'data/processed/'\n",
    "PROCESSED_TALIBAN_CSV = os.path.join(PROCESSED_TALIBAN_DIR, 'taliban_extracted_events.csv')\n",
    "VISUALIZATIONS_DIR = 'visualizations/'\n",
    "\n",
    "# Date for regime shift analysis\n",
    "TAKEOVER_DATE_STR = \"2021-08-15\"\n",
    "TAKEOVER_DATE = pd.to_datetime(TAKEOVER_DATE_STR)\n",
    "\n",
    "# Map Configuration\n",
    "AFGHANISTAN_CENTER_LAT = 33.93911\n",
    "AFGHANISTAN_CENTER_LON = 67.709953\n",
    "DEFAULT_MAP_ZOOM = 5\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (14, 7) # Default figure size\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "seed = 123 # For reproducibility in case of sampling\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(PROCESSED_TALIBAN_DIR, exist_ok=True)\n",
    "os.makedirs(VISUALIZATIONS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Cell 1: Imports and Configuration complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Raw Taliban articles file 'data/raw/english_extracted_articles.json' not found in project root or data/raw/.\n",
      "This notebook requires the output from 'src/scrapers/article_scraper.py'.\n",
      "A minimal DUMMY DataFrame will be created for demonstration, but EDA will not be meaningful.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.datetime64' object has no attribute 'strftime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m         df_taliban_raw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_taliban_raw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, date_obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(random_dates_dummy):\n\u001b[0;32m---> 24\u001b[0m             df_taliban_raw\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublication_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdate_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mB \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.datetime64' object has no attribute 'strftime'"
     ]
    }
   ],
   "source": [
    "# Attempt to load the primary scraped data file\n",
    "input_file_path = TALIBAN_SCRAPED_ARTICLES_JSON\n",
    "if not os.path.exists(input_file_path):\n",
    "    # Fallback to a common data/raw location\n",
    "    input_file_path_alt = os.path.join('data', 'raw', TALIBAN_SCRAPED_ARTICLES_JSON)\n",
    "    if os.path.exists(input_file_path_alt):\n",
    "        input_file_path = input_file_path_alt\n",
    "    else:\n",
    "        print(f\"ERROR: Raw Taliban articles file '{TALIBAN_SCRAPED_ARTICLES_JSON}' not found in project root or data/raw/.\")\n",
    "        print(\"This notebook requires the output from 'src/scrapers/article_scraper.py'.\")\n",
    "        print(\"A minimal DUMMY DataFrame will be created for demonstration, but EDA will not be meaningful.\")\n",
    "        df_taliban_raw = pd.DataFrame([\n",
    "            {'link': 'dummy1', 'title': 'Dummy Event 1', 'body': 'Content 1',\n",
    "             'metadata': {'publication_date': 'January 01, 2020'}, 'extracted_location': 'KABUL'},\n",
    "            {'link': 'dummy2', 'title': 'Dummy Event 2', 'body': 'Content 2',\n",
    "             'metadata': {'publication_date': 'September 15, 2021'}, 'extracted_location': 'HELMAND'}\n",
    "        ] * 100) # Multiply for some data volume\n",
    "        # Add varied dummy dates\n",
    "        np.random.seed(seed)\n",
    "        date_range_dummy = pd.date_range(start=\"2016-06-01\", end=\"2024-02-20\", freq='D')\n",
    "        random_dates_dummy = np.random.choice(date_range_dummy, size=len(df_taliban_raw))\n",
    "        df_taliban_raw['metadata'] = df_taliban_raw['metadata'].apply(lambda x: x.copy())\n",
    "        for i, date_obj in enumerate(random_dates_dummy):\n",
    "            df_taliban_raw.loc[i, 'metadata']['publication_date'] = date_obj.strftime(\"%B %d, %Y\")\n",
    "else:\n",
    "    try:\n",
    "        df_taliban_raw = pd.read_json(input_file_path)\n",
    "        print(f\"Successfully loaded raw Taliban articles from '{input_file_path}'. Shape: {df_taliban_raw.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred loading '{input_file_path}': {e}\")\n",
    "        df_taliban_raw = pd.DataFrame() # Ensure df_taliban_raw exists\n",
    "\n",
    "if df_taliban_raw.empty:\n",
    "    print(\"Critical Error: Taliban raw data is empty. Cannot proceed.\")\n",
    "else:\n",
    "    print(\"\\nColumns:\", df_taliban_raw.columns.tolist())\n",
    "    print(\"\\nFirst 2 rows (raw):\")\n",
    "    display(df_taliban_raw.head(2))\n",
    "\n",
    "# Make a working copy\n",
    "df_taliban = df_taliban_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_taliban_date(date_str):\n",
    "    \"\"\"Parses various date string formats found in Taliban article metadata.\"\"\"\n",
    "    if pd.isna(date_str) or not isinstance(date_str, str):\n",
    "        return pd.NaT\n",
    "    date_str = date_str.strip()\n",
    "    formats_to_try = [\n",
    "        \"%B %d, %Y\", \"%d %B %Y\", \"%b %d, %Y\", \"%d %b %Y\",\n",
    "        \"%B %d. %Y\", \"%d. %B %Y\", \"%Y-%m-%d\", \"%m/%d/%Y\", \"%d/%m/%Y\"\n",
    "    ]\n",
    "    for fmt in formats_to_try:\n",
    "        try: return datetime.strptime(date_str, fmt)\n",
    "        except ValueError: continue\n",
    "    date_str_cleaned = re.sub(r'(\\d+)(st|nd|rd|th)', r'\\1', date_str, flags=re.IGNORECASE)\n",
    "    if date_str_cleaned != date_str:\n",
    "        for fmt in formats_to_try:\n",
    "            try: return datetime.strptime(date_str_cleaned, fmt)\n",
    "            except ValueError: continue\n",
    "    match_slash_year = re.match(r\"(\\w+)\\s+(\\d+)\\s+/\\s+(\\d{4})\", date_str)\n",
    "    if match_slash_year:\n",
    "        month_str, day_str, year_str = match_slash_year.groups()\n",
    "        try: return datetime.strptime(f\"{month_str} {day_str} {year_str}\", \"%B %d %Y\")\n",
    "        except ValueError: pass # Try next if full month name fails\n",
    "        try: return datetime.strptime(f\"{month_str} {day_str} {year_str}\", \"%b %d %Y\")\n",
    "        except ValueError: pass\n",
    "    return pd.NaT\n",
    "\n",
    "if not df_taliban.empty:\n",
    "    print(\"\\n--- Parsing Dates ---\")\n",
    "    if 'metadata' in df_taliban.columns:\n",
    "        df_taliban['publication_date_str'] = df_taliban['metadata'].apply(\n",
    "            lambda x: x.get('publication_date') if isinstance(x, dict) else None\n",
    "        )\n",
    "        df_taliban['event_date'] = df_taliban['publication_date_str'].apply(parse_taliban_date)\n",
    "        \n",
    "        parsed_count = df_taliban['event_date'].notna().sum()\n",
    "        total_dates_to_parse = df_taliban['publication_date_str'].notna().sum()\n",
    "        print(f\"Successfully parsed {parsed_count} of {total_dates_to_parse} non-null publication date strings.\")\n",
    "        if parsed_count < total_dates_to_parse:\n",
    "            print(f\"  ({total_dates_to_parse - parsed_count} dates could not be parsed and are NaT).\")\n",
    "\n",
    "        df_taliban['year_month'] = df_taliban['event_date'].dt.to_period('M')\n",
    "        df_taliban['year'] = df_taliban['event_date'].dt.year # Add year column for filtering\n",
    "        print(\"Added 'event_date', 'year_month', 'year' columns.\")\n",
    "    else:\n",
    "        print(\"ERROR: 'metadata' column not found. Date processing skipped.\")\n",
    "        df_taliban['event_date'] = pd.NaT\n",
    "        df_taliban['year_month'] = pd.NaT\n",
    "        df_taliban['year'] = np.nan\n",
    "else:\n",
    "    print(\"DataFrame empty. Date parsing skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_taliban.empty:\n",
    "    print(\"\\n--- Cleaning and Geocoding Taliban Locations (using cache) ---\")\n",
    "\n",
    "    location_coordinates_dict = {}\n",
    "    geocode_cache_path = GEOCODE_CACHE_JSON\n",
    "    if not os.path.exists(geocode_cache_path):\n",
    "        # Fallback to data/intermediate if not in root\n",
    "        geocode_cache_path_alt = os.path.join('data', 'intermediate', GEOCODE_CACHE_JSON)\n",
    "        if os.path.exists(geocode_cache_path_alt):\n",
    "            geocode_cache_path = geocode_cache_path_alt\n",
    "        else:\n",
    "             print(f\"Warning: Geocode cache '{GEOCODE_CACHE_JSON}' not found in root or data/intermediate/. Heatmaps might be sparse.\")\n",
    "\n",
    "    if os.path.exists(geocode_cache_path):\n",
    "        try:\n",
    "            with open(geocode_cache_path, 'r', encoding='utf-8') as f:\n",
    "                cached_data = json.load(f)\n",
    "                for loc, coords in cached_data.items():\n",
    "                    if isinstance(coords, list) and len(coords) == 2:\n",
    "                        location_coordinates_dict[loc] = tuple(coords)\n",
    "                    else: location_coordinates_dict[loc] = None\n",
    "            print(f\"Loaded geocode cache '{geocode_cache_path}' with {len(location_coordinates_dict)} entries.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading geocode cache: {e}\")\n",
    "    else:\n",
    "        print(f\"Geocode cache not found at '{geocode_cache_path}'. Locations will not be geocoded in this notebook.\")\n",
    "\n",
    "    # Comprehensive cleaning map (ensure this matches the one used to create the cache)\n",
    "    cleaning_map = {\n",
    "        \"KABIL\": \"KABUL\", \"KAB\": \"KABUL\", # ... (Your full cleaning_map) ...\n",
    "        \"NANGARHRA\": \"NANGARHAR\", \"HLEMNAD\": \"HELMAND\", \"PAKTKIA\": \"PAKTIKA\",\n",
    "        \"NONE\": \"_IGNORE_\", \"L\": \"_IGNORE_\", \"KH\": \"_IGNORE_\", \"D\": \"_IGNORE_\", \"S\": \"_IGNORE_\", \"NA\": \"_IGNORE_\"\n",
    "    }\n",
    "\n",
    "    def clean_df_location_name(raw_name):\n",
    "        if pd.isna(raw_name) or not isinstance(raw_name, str) or not raw_name.strip(): return None\n",
    "        name_upper = raw_name.strip().upper()\n",
    "        if name_upper == 'NAN': return None\n",
    "        cleaned = cleaning_map.get(name_upper, name_upper)\n",
    "        return None if cleaned == \"_IGNORE_\" else cleaned\n",
    "\n",
    "    if 'extracted_location' in df_taliban.columns:\n",
    "        df_taliban['cleaned_location'] = df_taliban['extracted_location'].apply(clean_df_location_name)\n",
    "        df_taliban['latitude'] = df_taliban['cleaned_location'].apply(\n",
    "            lambda x: location_coordinates_dict.get(x)[0] if isinstance(location_coordinates_dict.get(x), tuple) else np.nan)\n",
    "        df_taliban['longitude'] = df_taliban['cleaned_location'].apply(\n",
    "            lambda x: location_coordinates_dict.get(x)[1] if isinstance(location_coordinates_dict.get(x), tuple) else np.nan)\n",
    "        \n",
    "        geocoded_count = df_taliban['latitude'].notna().sum()\n",
    "        print(f\"Applied location cleaning. Mapped coordinates for {geocoded_count} events from cache.\")\n",
    "    else:\n",
    "        print(\"ERROR: 'extracted_location' column not found. Location processing skipped.\")\n",
    "        df_taliban['cleaned_location'] = None; df_taliban['latitude'] = np.nan; df_taliban['longitude'] = np.nan\n",
    "else:\n",
    "    print(\"DataFrame empty. Location processing skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_taliban.empty and 'year_month' in df_taliban.columns and 'event_date' in df_taliban.columns:\n",
    "    print(\"\\n--- EDA: Figure 3 - Taliban Reports Over Time ---\")\n",
    "    \n",
    "    df_plot_fig3 = df_taliban.dropna(subset=['event_date']).sort_values('event_date')\n",
    "\n",
    "    if not df_plot_fig3.empty:\n",
    "        monthly_reports = df_plot_fig3.groupby('year_month').size()\n",
    "        if isinstance(monthly_reports.index, pd.PeriodIndex):\n",
    "            monthly_reports.index = monthly_reports.index.to_timestamp()\n",
    "\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.plot(monthly_reports.index, monthly_reports.values, marker='o', linestyle='-', color='orangered', markersize=5)\n",
    "        \n",
    "        plt.title('Number of Taliban Events per Month', fontsize=15) # Adjusted from Figure caption\n",
    "        plt.xlabel('Month', fontsize=12)\n",
    "        plt.ylabel('Number of Events', fontsize=12)\n",
    "        \n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "        plt.gca().xaxis.set_major_locator(mdates.YearLocator(1))\n",
    "        plt.gca().xaxis.set_minor_locator(mdates.MonthLocator(bymonth=[1,4,7,10])) # Quarterly minor ticks\n",
    "        plt.tick_params(axis='x', which='major', labelsize=10, rotation=0) # Keep years unrotated\n",
    "        plt.tick_params(axis='y', labelsize=10)\n",
    "\n",
    "        min_date_plot, max_date_plot = monthly_reports.index.min(), monthly_reports.index.max()\n",
    "        if pd.notna(min_date_plot) and pd.notna(max_date_plot) and min_date_plot <= TAKEOVER_DATE <= max_date_plot:\n",
    "             plt.axvline(TAKEOVER_DATE, color='steelblue', linestyle='--', lw=1.5, label=f'Taliban Takeover ({TAKEOVER_DATE_STR})')\n",
    "             plt.legend(fontsize=10)\n",
    "\n",
    "        plt.grid(True, which='major', linestyle='-', linewidth='0.5', color='darkgrey')\n",
    "        plt.grid(True, which='minor', linestyle=':', linewidth='0.3', color='lightgrey')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        fig3_path = os.path.join(VISUALIZATIONS_DIR, 'figure3_taliban_reports_over_time.png')\n",
    "        plt.savefig(fig3_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Figure 3 saved to {fig3_path}\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No data with valid dates to plot for Figure 3.\")\n",
    "else:\n",
    "    print(\"DataFrame empty or required date columns missing. Skipping Figure 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_taliban.empty and 'latitude' in df_taliban.columns and 'longitude' in df_taliban.columns and 'event_date' in df_taliban.columns:\n",
    "    print(\"\\n--- EDA: Figure 4 & 5 - Pre/Post Takeover Location Heatmaps ---\")\n",
    "\n",
    "    df_taliban_geocoded = df_taliban.dropna(subset=['latitude', 'longitude', 'event_date'])\n",
    "    if df_taliban_geocoded.empty:\n",
    "        print(\"No geocoded Taliban events with valid dates available for heatmaps.\")\n",
    "    else:\n",
    "        df_pre_takeover = df_taliban_geocoded[df_taliban_geocoded['event_date'] < TAKEOVER_DATE]\n",
    "        df_post_takeover = df_taliban_geocoded[df_taliban_geocoded['event_date'] >= TAKEOVER_DATE]\n",
    "\n",
    "        print(f\"Events for Pre-Takeover Heatmap: {len(df_pre_takeover)}\")\n",
    "        print(f\"Events for Post-Takeover Heatmap: {len(df_post_takeover)}\")\n",
    "\n",
    "        def create_heatmap(df_period, period_name, figure_num_str, output_filename):\n",
    "            if not df_period.empty:\n",
    "                # Filter out potential outliers or data points far from Afghanistan for map focus\n",
    "                df_map_filtered = df_period[\n",
    "                    (df_period['latitude'] > 29) & (df_period['latitude'] < 39) &\n",
    "                    (df_period['longitude'] > 60) & (df_period['longitude'] < 75)\n",
    "                ]\n",
    "                \n",
    "                if df_map_filtered.empty:\n",
    "                    print(f\"No data points within Afghanistan's approximate bounds for {period_name} heatmap.\")\n",
    "                    return\n",
    "\n",
    "                map_viz = folium.Map(location=[AFGHANISTAN_CENTER_LAT, AFGHANISTAN_CENTER_LON], \n",
    "                                     zoom_start=DEFAULT_MAP_ZOOM, \n",
    "                                     tiles=\"CartoDB positron\") # Using a subtle base map\n",
    "                folium.TileLayer('openstreetmap', name=\"Street Map View\").add_to(map_viz)\n",
    "                \n",
    "                heat_data = [[row['latitude'], row['longitude']] for idx, row in df_map_filtered.iterrows()]\n",
    "                \n",
    "                if heat_data:\n",
    "                    HeatMap(heat_data, \n",
    "                            name=f\"{period_name} Event Density\", \n",
    "                            radius=15, # Adjust for visual preference\n",
    "                            blur=12,   # Adjust for visual preference\n",
    "                            max_zoom=4 # Prevent heatmap from becoming too sparse on zoom\n",
    "                           ).add_to(map_viz)\n",
    "                    folium.LayerControl().add_to(map_viz)\n",
    "                    \n",
    "                    map_path = os.path.join(VISUALIZATIONS_DIR, output_filename)\n",
    "                    map_viz.save(map_path)\n",
    "                    print(f\"Figure {figure_num_str} ({period_name} Heatmap) saved to {map_path}\")\n",
    "                    # display(map_viz) # Uncomment to display inline\n",
    "                else:\n",
    "                    print(f\"No valid heat data for {period_name} heatmap after filtering.\")\n",
    "            else:\n",
    "                print(f\"No data for {period_name} to generate heatmap.\")\n",
    "\n",
    "        # --- Figure 4: Pre-Takeover Heatmap ---\n",
    "        create_heatmap(df_pre_takeover, \"Pre-Takeover\", \"4\", 'figure4_heatmap_pre_takeover.html')\n",
    "\n",
    "        # --- Figure 5: Post-Takeover Heatmap ---\n",
    "        create_heatmap(df_post_takeover, \"Post-Takeover\", \"5\", 'figure5_heatmap_post_takeover.html')\n",
    "else:\n",
    "    print(\"DataFrame empty or coordinate/date columns missing. Skipping Heatmaps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_taliban.empty:\n",
    "    # Define relevant columns for the final processed output\n",
    "    columns_to_save = [\n",
    "        'link', 'title', 'body', # Core article info\n",
    "        'publication_date_str', 'event_date', 'year_month', 'year', # Date info\n",
    "        'extracted_location', 'cleaned_location', 'latitude', 'longitude', # Location info\n",
    "        'metadata' # Keep raw metadata if needed for other analyses\n",
    "    ]\n",
    "    \n",
    "    # Ensure all selected columns exist; create with NaNs if not (though they should be by now)\n",
    "    df_taliban_processed = pd.DataFrame()\n",
    "    for col in columns_to_save:\n",
    "        if col in df_taliban.columns:\n",
    "            df_taliban_processed[col] = df_taliban[col]\n",
    "        else:\n",
    "            df_taliban_processed[col] = np.nan\n",
    "            print(f\"Warning: Column '{col}' was missing from df_taliban, added with NaNs for saving.\")\n",
    "            \n",
    "    try:\n",
    "        df_taliban_processed.to_csv(PROCESSED_TALIBAN_CSV, index=False)\n",
    "        print(f\"\\nProcessed Taliban data saved to '{PROCESSED_TALIBAN_CSV}'\")\n",
    "        # Optional: Save to Excel (requires openpyxl)\n",
    "        # df_taliban_processed.to_excel(PROCESSED_TALIBAN_XLSX, index=False, engine='openpyxl')\n",
    "        # print(f\"Processed Taliban data also saved to '{PROCESSED_TALIBAN_XLSX}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving processed Taliban data: {e}\")\n",
    "        \n",
    "    print(\"\\nFinal processed Taliban DataFrame sample:\")\n",
    "    display(df_taliban_processed.head(3))\n",
    "    print(f\"Shape: {df_taliban_processed.shape}\")\n",
    "else:\n",
    "    print(\"DataFrame is empty. Nothing to save.\")\n",
    "\n",
    "print(\"\\n--- Notebook 2: Taliban Exploration and Data Preparation Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
